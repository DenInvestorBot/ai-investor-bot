import os
import re
import traceback
from typing import List, Dict, Tuple

import praw
from openai import OpenAI

from crypto_monitor import send_to_telegram, _escape_markdown

print("[reddit_monitor] module loaded")

# --- ENV ---
REDDIT_CLIENT_ID = os.getenv("REDDIT_CLIENT_ID")
REDDIT_CLIENT_SECRET = os.getenv("REDDIT_CLIENT_SECRET")
REDDIT_USER_AGENT = os.getenv("REDDIT_USER_AGENT", "ai-investor-bot/1.0")

SUBS = [s.strip() for s in os.getenv("REDDIT_SUBS", "wallstreetbets").split(",") if s.strip()]
DEFAULT_TICKERS = "GME,RBNE,TSLA,AAPL,NVDA,MSFT,AMZN,META,NFLX,AMD"
TICKERS: List[str] = [t.strip().upper() for t in os.getenv("REDDIT_TICKERS", DEFAULT_TICKERS).split(",") if t.strip()]

OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")
SUMMARIZE = os.getenv("REDDIT_SUMMARIZE", "1")  # "1"=on, "0"=off
client = OpenAI(api_key=OPENAI_API_KEY) if (OPENAI_API_KEY and SUMMARIZE != "0") else None

# --- Helpers ---
def _compile_patterns(tickers: List[str]) -> Dict[str, re.Pattern]:
    # –£—á–∏—Ç—ã–≤–∞–µ–º $TSLA –∏ –≥—Ä–∞–Ω–∏—Ü—ã —Å–ª–æ–≤–∞
    return {t: re.compile(rf"\b\$?{re.escape(t)}\b", flags=re.IGNORECASE) for t in tickers}

def _count_mentions_and_collect(
    text: str,
    patterns: Dict[str, re.Pattern],
    store: Dict[str, List[str]],
    title: str,
    limit_per_ticker: int = 12,
) -> Dict[str, int]:
    counts = {}
    for t, pat in patterns.items():
        hits = len(pat.findall(text))
        if hits:
            counts[t] = counts.get(t, 0) + hits
            # –∫–æ–ø–∏–º –∑–∞–≥–æ–ª–æ–≤–∫–∏ –¥–ª—è –ø–æ—Å–ª–µ–¥—É—é—â–µ–≥–æ —Ä–µ–∑—é–º–µ
            if len(store[t]) < limit_per_ticker:
                # –∫–æ—Ä–æ—Ç–∫–æ –Ω–æ—Ä–º–∞–ª–∏–∑—É–µ–º –∑–∞–≥–æ–ª–æ–≤–∫–∏
                cleaned = re.sub(r"\s+", " ", title).strip()
                store[t].append(cleaned)
    return counts

def _summarize_ticker(ticker: str, titles: List[str]) -> str:
    """–ö–æ—Ä–æ—Ç–∫–æ–µ —Ä–µ–∑—é–º–µ –æ–±—Å—É–∂–¥–µ–Ω–∏–π —Ç–∏–∫–µ—Ä–∞ –ø–æ –∑–∞–≥–æ–ª–æ–≤–∫–∞–º –ø–æ—Å—Ç–æ–≤."""
    if not titles:
        return "–û–±—Å—É–∂–¥–µ–Ω–∏–π –º–∞–ª–æ/–Ω–µ –≤—ã—è–≤–ª–µ–Ω–æ."
    if not client:
        # –§–æ–ª–ª–±—ç–∫ –±–µ–∑ AI: –ø–æ–∫–∞–∂–µ–º 2‚Äì3 —Ö–∞—Ä–∞–∫—Ç–µ—Ä–Ω—ã—Ö –∑–∞–≥–æ–ª–æ–≤–∫–∞
        sample = "; ".join(titles[:3])
        return f"–ì–ª–∞–≤–Ω–æ–µ –ø–æ –∑–∞–≥–æ–ª–æ–≤–∫–∞–º: {sample}"

    joined = "\n".join(f"- {t}" for t in titles[:10])
    prompt = (
        "–°—É–º–º–∏—Ä—É–π –≤ 1‚Äì2 –∫—Ä–∞—Ç–∫–∏—Ö –ø—É–Ω–∫—Ç–∞—Ö (–Ω–∞ —Ä—É—Å—Å–∫–æ–º), —á—Ç–æ –∏–º–µ–Ω–Ω–æ –æ–±—Å—É–∂–¥–∞—é—Ç –Ω–∞ Reddit –ø—Ä–æ —Ç–∏–∫–µ—Ä. "
        "–ì–æ–≤–æ—Ä–∏ –ø–æ –¥–µ–ª—É: –¥—Ä–∞–π–≤–µ—Ä—ã —Ä–æ—Å—Ç–∞/–ø–∞–¥–µ–Ω–∏—è, –Ω–æ–≤–æ—Å—Ç–∏, –æ—Ç—á—ë—Ç—ã, —Å–ª—É—Ö–∏, —Å—Ç—Ä–∞—Ç–µ–≥–∏—è. "
        "–ò—Å–ø–æ–ª—å–∑—É–π –º–∞–∫—Å–∏–º—É–º 220 —Å–∏–º–≤–æ–ª–æ–≤ –Ω–∞ –≤—Å—ë —Ä–µ–∑—é–º–µ.\n\n"
        f"–¢–∏–∫–µ—Ä: {ticker}\n"
        f"–ó–∞–≥–æ–ª–æ–≤–∫–∏ –ø–æ—Å—Ç–æ–≤:\n{joined}"
    )
    try:
        resp = client.chat.completions.create(
            model="gpt-4o-mini",
            messages=[{"role": "user", "content": prompt}],
            temperature=0.2,
            max_tokens=120,
        )
        text = (resp.choices[0].message.content or "").strip()
        return text
    except Exception:
        traceback.print_exc()
        sample = "; ".join(titles[:3])
        return f"–ì–ª–∞–≤–Ω–æ–µ –ø–æ –∑–∞–≥–æ–ª–æ–≤–∫–∞–º: {sample}"

# --- Main ---
def run_reddit_monitor():
    print("[reddit_monitor] start")
    if not (REDDIT_CLIENT_ID and REDDIT_CLIENT_SECRET):
        msg = "‚ö†Ô∏è –ù–µ –∑–∞–¥–∞–Ω—ã Reddit –∫—Ä–µ–¥—ã (REDDIT_CLIENT_ID/SECRET)."
        print(f"[reddit_monitor] {msg}")
        send_to_telegram(_escape_markdown(msg))
        return

    try:
        reddit = praw.Reddit(
            client_id=REDDIT_CLIENT_ID,
            client_secret=REDDIT_CLIENT_SECRET,
            user_agent=REDDIT_USER_AGENT,
            check_for_async=False,
        )
        print("[reddit_monitor] Reddit client OK")
    except Exception:
        print("[reddit_monitor] failed to create Reddit client:")
        traceback.print_exc()
        send_to_telegram(_escape_markdown("‚ùå –û—à–∏–±–∫–∞ Reddit: –Ω–µ —É–¥–∞–ª–æ—Å—å –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å –∫–ª–∏–µ–Ω—Ç."))
        return

    patterns = _compile_patterns(TICKERS)
    mention_counts: Dict[str, int] = {t: 0 for t in TICKERS}
    titles_store: Dict[str, List[str]] = {t: [] for t in TICKERS}

    try:
        for sub in SUBS:
            print(f"[reddit_monitor] scanning r/{sub}")
            for post in reddit.subreddit(sub).new(limit=120):
                title = (post.title or "").strip()
                selftext = (getattr(post, "selftext", "") or "").strip()
                text = f"{title}\n{selftext}"
                local = _count_mentions_and_collect(text, patterns, titles_store, title)
                for k, v in local.items():
                    mention_counts[k] = mention_counts.get(k, 0) + v
    except Exception:
        print("[reddit_monitor] error while collecting posts:")
        traceback.print_exc()
        send_to_telegram(_escape_markdown("‚ùå –û—à–∏–±–∫–∞ Reddit –ø—Ä–∏ —Å–±–æ—Ä–µ –¥–∞–Ω–Ω—ã—Ö."))
        return

    # —É–±–∏—Ä–∞–µ–º –Ω—É–ª–∏
    mention_counts = {k: v for k, v in mention_counts.items() if v > 0}
    if not mention_counts:
        msg = "‚ùóÔ∏è –í Reddit –Ω–µ—Ç —É–ø–æ–º–∏–Ω–∞–Ω–∏–π –∏–∑ —Å–ø–∏—Å–∫–∞ —Ç–∏–∫–µ—Ä–æ–≤."
        print(f"[reddit_monitor] {msg}")
        send_to_telegram(_escape_markdown(msg))
        return

    # –¢–æ–ø-3 –ø–æ —É–ø–æ–º–∏–Ω–∞–Ω–∏—è–º
    top3: List[Tuple[str, int]] = sorted(mention_counts.items(), key=lambda x: x[1], reverse=True)[:3]

    # –§–æ—Ä–º–∏—Ä—É–µ–º —Ä–µ–∑—é–º–µ –¥–ª—è –∫–∞–∂–¥–æ–≥–æ
    lines = ["üìà *Reddit –¢–æ–ø-—Ç–∏–∫–µ—Ä—ã –¥–Ω—è:*", ""]
    for ticker, count in top3:
        summary = _summarize_ticker(ticker, titles_store.get(ticker, []))
        line = f"*{_escape_markdown(ticker)}* ‚Äî {count} —É–ø–æ–º–∏–Ω–∞–Ω–∏–π\n" \
               f"{_escape_markdown(summary)}"
        lines.append(line)
        lines.append("")  # –ø—É—Å—Ç–∞—è —Å—Ç—Ä–æ–∫–∞ –º–µ–∂–¥—É —Ç–∏–∫–µ—Ä–∞–º–∏

    msg = "\n".join(lines).strip()
    send_to_telegram(msg)
    print(f"[reddit_monitor] report sent. top3={top3}")
